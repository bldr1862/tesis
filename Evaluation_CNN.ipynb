{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bldr1\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import params\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import xlsxwriter\n",
    "from collections import defaultdict\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHOOSE 1000 TEST QUERIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "captions = utils.readCaptions(params.VAL_CAPTIONS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'caption': 'A bicycle replica with a clock as the front wheel.',\n",
       " 'id': 37,\n",
       " 'image_id': 203564}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N = 1011\\ncaptions_idxs = np.arange(captions.__len__())\\nnp.random.shuffle(captions_idxs)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"N = 1011\n",
    "captions_idxs = np.arange(captions.__len__())\n",
    "np.random.shuffle(captions_idxs)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"captions_dict = {}\\nfor caption_idx in tqdm(captions_idxs[:N]):\\n    caption = captions[caption_idx]['caption']\\n    caption_id = captions[caption_idx]['image_id']\\n    caption_tfidf = np.load( params.TFIDF_DESCRIPTORS_VAL_PATH+str(caption_id)+'.npy').tolist()[0]\\n    caption_rtfidf = np.load( params.REDUCED_TFIDF_DESCRIPTORS_VAL_PATH+str(caption_id)+'.npy').tolist()[0]\\n    caption_w2v = np.load(  params.W2V_DESCRIPTORS_VAL_PATH+str(caption_id)+'.npy' )[0]\\n    captions_dict[str(caption_id)] = {}\\n    captions_dict[str(caption_id)]['caption'] = caption\\n    captions_dict[str(caption_id)]['tfidf'] = caption_tfidf\\n    captions_dict[str(caption_id)]['r-tfidf'] = caption_rtfidf\\n    captions_dict[str(caption_id)]['w2v'] = caption_w2v\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"captions_dict = {}\n",
    "for caption_idx in tqdm(captions_idxs[:N]):\n",
    "    caption = captions[caption_idx]['caption']\n",
    "    caption_id = captions[caption_idx]['image_id']\n",
    "    caption_tfidf = np.load( params.TFIDF_DESCRIPTORS_VAL_PATH+str(caption_id)+'.npy').tolist()[0]\n",
    "    caption_rtfidf = np.load( params.REDUCED_TFIDF_DESCRIPTORS_VAL_PATH+str(caption_id)+'.npy').tolist()[0]\n",
    "    caption_w2v = np.load(  params.W2V_DESCRIPTORS_VAL_PATH+str(caption_id)+'.npy' )[0]\n",
    "    captions_dict[str(caption_id)] = {}\n",
    "    captions_dict[str(caption_id)]['caption'] = caption\n",
    "    captions_dict[str(caption_id)]['tfidf'] = caption_tfidf\n",
    "    captions_dict[str(caption_id)]['r-tfidf'] = caption_rtfidf\n",
    "    captions_dict[str(caption_id)]['w2v'] = caption_w2v\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'captions_dict.keys().__len__()'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"captions_dict.keys().__len__()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"utils.savePickle(object=captions_dict, PATH='TMP/test_captions')\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"utils.savePickle(object=captions_dict, PATH='TMP/test_captions')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"test_captions = utils.importPickle('TMP/test_captions')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OUTPUT_SHAPE = 128\n",
    "TFIDF_CNN_WEIGHTS = 'TMP/model_tfidf_cnn_pca_dropout_02.h5'\n",
    "RTFIDF_CNN_WEIGHTS = 'TMP/model_reduced_tfidf_cnn_pca_dropout_02.h5'\n",
    "W2V_CNN_WEIGHTS = 'TMP/model_w2v_cnn_pca_dropout_02.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_SHAPE = 369537\n",
    "tfidf_model = Sequential()\n",
    "tfidf_model.add(Dense(input_dim=INPUT_SHAPE, units = 150, kernel_initializer='normal'))\n",
    "tfidf_model.add(Activation('relu'))\n",
    "tfidf_model.add(Dropout(0.2))\n",
    "tfidf_model.add(Dense(units = 130, kernel_initializer='normal'))\n",
    "tfidf_model.add(Activation('relu'))\n",
    "tfidf_model.add(Dropout(0.2))\n",
    "tfidf_model.add(Dense(units = OUTPUT_SHAPE, kernel_initializer='normal'))\n",
    "tfidf_model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "tfidf_model.load_weights(TFIDF_CNN_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_SHAPE = 91155\n",
    "rtfidf_model = Sequential()\n",
    "rtfidf_model.add(Dense(input_dim=INPUT_SHAPE, units = 150, kernel_initializer='normal'))\n",
    "rtfidf_model.add(Activation('relu'))\n",
    "rtfidf_model.add(Dropout(0.2))\n",
    "rtfidf_model.add(Dense(units = 130, kernel_initializer='normal'))\n",
    "rtfidf_model.add(Activation('relu'))\n",
    "rtfidf_model.add(Dropout(0.2))\n",
    "rtfidf_model.add(Dense(units = OUTPUT_SHAPE, kernel_initializer='normal'))\n",
    "rtfidf_model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "rtfidf_model.load_weights(RTFIDF_CNN_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_SHAPE = 300\n",
    "w2v_model = Sequential()\n",
    "w2v_model.add(Dense(input_dim=INPUT_SHAPE, units = 150, kernel_initializer='normal'))\n",
    "w2v_model.add(Activation('relu'))\n",
    "w2v_model.add(Dropout(0.2))\n",
    "w2v_model.add(Dense(units = 130, kernel_initializer='normal'))\n",
    "w2v_model.add(Activation('relu'))\n",
    "w2v_model.add(Dropout(0.2))\n",
    "w2v_model.add(Dense(units = OUTPUT_SHAPE, kernel_initializer='normal'))\n",
    "w2v_model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "w2v_model.load_weights(W2V_CNN_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = utils.importPickle(params.CNN_VAL_INDEX)\n",
    "order = utils.importPickle(params.CNN_VAL_ORDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:52<00:00,  8.88it/s]\n"
     ]
    }
   ],
   "source": [
    "for key in tqdm(captions_dict.keys()):\n",
    "    tfidf_pred = tfidf_model.predict(captions_dict[key]['tfidf'])\n",
    "    rtfidf_pred = rtfidf_model.predict(captions_dict[key]['r-tfidf'])\n",
    "    w2v_pred = w2v_model.predict(captions_dict[key]['w2v'].reshape(-1,300))\n",
    "      \n",
    "    tfidf_dist, tfidf_idxs = tree.query(tfidf_pred/np.linalg.norm(tfidf_pred), k=10)\n",
    "    rtfidf_dist, rtfidf_idxs = tree.query(rtfidf_pred/np.linalg.norm(rtfidf_pred), k=10)\n",
    "    w2v_dist, w2v_idxs = tree.query(w2v_pred/np.linalg.norm(w2v_pred), k=10)\n",
    "    \n",
    "    tfidf_images = [order[i] for i in tfidf_idxs[0]] \n",
    "    rtfidf_images = [order[i] for i in rtfidf_idxs[0]]\n",
    "    w2v_images = [order[i] for i in w2v_idxs[0]]\n",
    "    \n",
    "    tfidf_paths = [params.VAL_IMAGES_PATH + os.path.basename(image).split('.')[0][4:]+'.jpg' for image in tfidf_images]\n",
    "    rtfidf_paths = [params.VAL_IMAGES_PATH + os.path.basename(image).split('.')[0][4:]+'.jpg' for image in rtfidf_images]\n",
    "    w2v_paths = [params.VAL_IMAGES_PATH + os.path.basename(image).split('.')[0][4:]+'.jpg' for image in w2v_images]\n",
    "    \n",
    "    captions_dict[key]['tfidf_paths'] = tfidf_paths\n",
    "    captions_dict[key]['rtfidf_paths'] = rtfidf_paths\n",
    "    captions_dict[key]['w2v_paths'] = w2v_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utils.savePickle(captions_dict,'TMP/cnn_captions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphabet = ['C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', \n",
    "            'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:29<00:00,  3.39it/s]\n",
      "100%|██████████| 100/100 [00:36<00:00,  2.75it/s]\n",
      "100%|██████████| 100/100 [00:39<00:00,  2.54it/s]\n",
      "100%|██████████| 100/100 [00:33<00:00,  2.96it/s]\n",
      "100%|██████████| 100/100 [00:29<00:00,  3.35it/s]\n",
      "100%|██████████| 100/100 [00:29<00:00,  3.40it/s]\n",
      "100%|██████████| 100/100 [00:25<00:00,  3.92it/s]\n",
      "100%|██████████| 100/100 [00:26<00:00,  3.80it/s]\n",
      "100%|██████████| 100/100 [00:29<00:00,  3.43it/s]\n",
      "100%|██████████| 100/100 [00:27<00:00,  3.63it/s]\n"
     ]
    }
   ],
   "source": [
    "for counter in range(10):\n",
    "    tfidf_workbook = xlsxwriter.Workbook('EXCELS/TFIDF_CNN/tfidf_cnn_{}.xlsx'.format(counter))\n",
    "    tfidf_worksheet = tfidf_workbook.add_worksheet()\n",
    "    tfidf_worksheet.set_column('A:A', 10)\n",
    "    tfidf_worksheet.set_column('B:B', 60)\n",
    "    tfidf_worksheet.write('A1','POSITION')\n",
    "\n",
    "    j = 4\n",
    "    for key in tqdm(list(captions_dict.keys())[counter*100:counter*100+100]):\n",
    "        caption = captions_dict[key]['caption']\n",
    "        tfidf_paths = captions_dict[key]['tfidf_paths']\n",
    "        #rtfidf_paths = captions_dict[key]['rtfidf_paths']\n",
    "        #w2v_paths = captions_dict[key]['w2v_paths']\n",
    "\n",
    "\n",
    "\n",
    "        tfidf_worksheet.write('B{}'.format(j), caption)\n",
    "        for i, path in enumerate(tfidf_paths):\n",
    "            img = image.load_img(path, target_size=(224, 224))\n",
    "            name = 'CROP/'+os.path.basename(path)\n",
    "            image.save_img(name, img)\n",
    "            tfidf_worksheet.insert_image('{}{}'.format(alphabet[i*2], j-2), \n",
    "                                         name, \n",
    "                                         {'x_scale': 0.5, 'y_scale': 0.5})\n",
    "\n",
    "        j = j+6\n",
    "    tfidf_workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:28<00:00,  3.54it/s]\n",
      "100%|██████████| 100/100 [00:25<00:00,  3.87it/s]\n",
      "100%|██████████| 100/100 [00:29<00:00,  3.37it/s]\n",
      "100%|██████████| 100/100 [00:28<00:00,  3.46it/s]\n",
      "100%|██████████| 100/100 [00:38<00:00,  2.61it/s]\n",
      "100%|██████████| 100/100 [00:24<00:00,  4.05it/s]\n",
      "100%|██████████| 100/100 [00:24<00:00,  4.09it/s]\n",
      "100%|██████████| 100/100 [00:24<00:00,  4.01it/s]\n",
      "100%|██████████| 100/100 [00:25<00:00,  3.91it/s]\n",
      "100%|██████████| 100/100 [00:28<00:00,  3.55it/s]\n"
     ]
    }
   ],
   "source": [
    "for counter in range(10):\n",
    "    rtfidf_workbook = xlsxwriter.Workbook('EXCELS/R-TFIDF_CNN/rtfidf_cnn_{}.xlsx'.format(counter))\n",
    "    rtfidf_worksheet = rtfidf_workbook.add_worksheet()\n",
    "    rtfidf_worksheet.set_column('A:A', 10)\n",
    "    rtfidf_worksheet.set_column('B:B', 60)\n",
    "    rtfidf_worksheet.write('A1','POSITION')\n",
    "\n",
    "    j = 4\n",
    "    for key in tqdm(list(captions_dict.keys())[counter*100:counter*100+100]):\n",
    "        caption = captions_dict[key]['caption']\n",
    "        rtfidf_paths = captions_dict[key]['rtfidf_paths']\n",
    "        #rtfidf_paths = captions_dict[key]['rtfidf_paths']\n",
    "        #w2v_paths = captions_dict[key]['w2v_paths']\n",
    "\n",
    "\n",
    "\n",
    "        rtfidf_worksheet.write('B{}'.format(j), caption)\n",
    "        for i, path in enumerate(rtfidf_paths):\n",
    "            img = image.load_img(path, target_size=(224, 224))\n",
    "            name = 'CROP/'+os.path.basename(path)\n",
    "            image.save_img(name, img)\n",
    "            rtfidf_worksheet.insert_image('{}{}'.format(alphabet[i*2], j-2), \n",
    "                                         name, \n",
    "                                         {'x_scale': 0.5, 'y_scale': 0.5})\n",
    "\n",
    "        j = j+6\n",
    "    rtfidf_workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:30<00:00,  3.28it/s]\n",
      "100%|██████████| 100/100 [00:41<00:00,  2.41it/s]\n",
      "100%|██████████| 100/100 [00:30<00:00,  3.23it/s]\n",
      "100%|██████████| 100/100 [00:25<00:00,  3.94it/s]\n",
      "100%|██████████| 100/100 [00:26<00:00,  3.81it/s]\n",
      "100%|██████████| 100/100 [00:24<00:00,  4.11it/s]\n",
      "100%|██████████| 100/100 [00:24<00:00,  4.08it/s]\n",
      "100%|██████████| 100/100 [00:25<00:00,  3.92it/s]\n",
      "100%|██████████| 100/100 [00:27<00:00,  3.70it/s]\n",
      "100%|██████████| 100/100 [00:25<00:00,  3.85it/s]\n"
     ]
    }
   ],
   "source": [
    "for counter in range(10):\n",
    "    w2v_workbook = xlsxwriter.Workbook('EXCELS/W2V_CNN/w2v_cnn_{}.xlsx'.format(counter))\n",
    "    w2v_worksheet = w2v_workbook.add_worksheet()\n",
    "    w2v_worksheet.set_column('A:A', 10)\n",
    "    w2v_worksheet.set_column('B:B', 60)\n",
    "    w2v_worksheet.write('A1','POSITION')\n",
    "\n",
    "    j = 4\n",
    "    for key in tqdm(list(captions_dict.keys())[counter*100:counter*100+100]):\n",
    "        caption = captions_dict[key]['caption']\n",
    "        w2v_paths = captions_dict[key]['w2v_paths']\n",
    "        #rtfidf_paths = captions_dict[key]['rtfidf_paths']\n",
    "        #w2v_paths = captions_dict[key]['w2v_paths']\n",
    "\n",
    "\n",
    "\n",
    "        w2v_worksheet.write('B{}'.format(j), caption)\n",
    "        for i, path in enumerate(w2v_paths):\n",
    "            img = image.load_img(path, target_size=(224, 224))\n",
    "            name = 'CROP/'+os.path.basename(path)\n",
    "            image.save_img(name, img)\n",
    "            w2v_worksheet.insert_image('{}{}'.format(alphabet[i*2], j-2), \n",
    "                                         name, \n",
    "                                         {'x_scale': 0.5, 'y_scale': 0.5})\n",
    "\n",
    "        j = j+6\n",
    "    w2v_workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
