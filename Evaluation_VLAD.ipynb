{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bldr1\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import params\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import xlsxwriter\n",
    "from collections import defaultdict\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHOOSE 1000 TEST QUERIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "captions = utils.readCaptions(params.VAL_CAPTIONS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"N = 1011\n",
    "captions_idxs = np.arange(captions.__len__())\n",
    "np.random.shuffle(captions_idxs)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"captions_dict = {}\n",
    "for caption_idx in tqdm(captions_idxs[:N]):\n",
    "    caption = captions[caption_idx]['caption']\n",
    "    caption_id = captions[caption_idx]['image_id']\n",
    "    caption_tfidf = np.load( params.TFIDF_DESCRIPTORS_VAL_PATH+str(caption_id)+'.npy').tolist()[0]\n",
    "    caption_rtfidf = np.load( params.REDUCED_TFIDF_DESCRIPTORS_VAL_PATH+str(caption_id)+'.npy').tolist()[0]\n",
    "    caption_w2v = np.load(  params.W2V_DESCRIPTORS_VAL_PATH+str(caption_id)+'.npy' )[0]\n",
    "    captions_dict[str(caption_id)] = {}\n",
    "    captions_dict[str(caption_id)]['caption'] = caption\n",
    "    captions_dict[str(caption_id)]['tfidf'] = caption_tfidf\n",
    "    captions_dict[str(caption_id)]['r-tfidf'] = caption_rtfidf\n",
    "    captions_dict[str(caption_id)]['w2v'] = caption_w2v\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"captions_dict.keys().__len__()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"utils.savePickle(object=captions_dict, PATH='TMP/test_captions')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "captions_dict = utils.importPickle('TMP/test_captions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OUTPUT_SHAPE = 128\n",
    "TFIDF_WEIGHTS = 'TMP/model_tfidf_vlad_pca_dropout_02.h5'\n",
    "RTFIDF_WEIGHTS = 'TMP/model_reduced_tfidf_vlad_pca_dropout_02.h5'\n",
    "W2V_WEIGHTS = 'TMP/model_w2v_vlad_pca_dropout_02.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_SHAPE = 369537\n",
    "tfidf_model = Sequential()\n",
    "tfidf_model.add(Dense(input_dim=INPUT_SHAPE, units = 150, kernel_initializer='normal'))\n",
    "tfidf_model.add(Activation('relu'))\n",
    "tfidf_model.add(Dropout(0.2))\n",
    "tfidf_model.add(Dense(units = 130, kernel_initializer='normal'))\n",
    "tfidf_model.add(Activation('relu'))\n",
    "tfidf_model.add(Dropout(0.2))\n",
    "tfidf_model.add(Dense(units = OUTPUT_SHAPE, kernel_initializer='normal'))\n",
    "tfidf_model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "tfidf_model.load_weights(TFIDF_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_SHAPE = 91155\n",
    "rtfidf_model = Sequential()\n",
    "rtfidf_model.add(Dense(input_dim=INPUT_SHAPE, units = 150, kernel_initializer='normal'))\n",
    "rtfidf_model.add(Activation('relu'))\n",
    "rtfidf_model.add(Dropout(0.2))\n",
    "rtfidf_model.add(Dense(units = 130, kernel_initializer='normal'))\n",
    "rtfidf_model.add(Activation('relu'))\n",
    "rtfidf_model.add(Dropout(0.2))\n",
    "rtfidf_model.add(Dense(units = OUTPUT_SHAPE, kernel_initializer='normal'))\n",
    "rtfidf_model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "rtfidf_model.load_weights(RTFIDF_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_SHAPE = 300\n",
    "w2v_model = Sequential()\n",
    "w2v_model.add(Dense(input_dim=INPUT_SHAPE, units = 150, kernel_initializer='normal'))\n",
    "w2v_model.add(Activation('relu'))\n",
    "w2v_model.add(Dropout(0.2))\n",
    "w2v_model.add(Dense(units = 130, kernel_initializer='normal'))\n",
    "w2v_model.add(Activation('relu'))\n",
    "w2v_model.add(Dropout(0.2))\n",
    "w2v_model.add(Dense(units = OUTPUT_SHAPE, kernel_initializer='normal'))\n",
    "w2v_model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "w2v_model.load_weights(W2V_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = utils.importPickle(params.VLAD_VAL_INDEX)\n",
    "order = utils.importPickle(params.VLAD_VAL_ORDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"captions_dict = utils.importPickle('TMP/cnn_captions')\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"captions_dict = utils.importPickle('TMP/cnn_captions')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'caption': 'A person on a motor bike on a street.',\n",
       " 'r-tfidf': <1x91155 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 9 stored elements in Compressed Sparse Row format>,\n",
       " 'tfidf': <1x369537 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 9 stored elements in Compressed Sparse Row format>,\n",
       " 'w2v': array([-2.4500e-02, -1.3288e-01, -7.0820e-02, -1.3780e-02, -7.8200e-03,\n",
       "        -5.5000e-03,  6.7920e-02,  7.0820e-02, -8.1000e-03, -3.2000e-03,\n",
       "         5.8680e-02,  6.9800e-02,  1.5888e-01,  5.8780e-02,  8.7180e-02,\n",
       "         7.4220e-02, -3.3020e-02,  3.0000e-04, -2.2700e-02, -5.9740e-02,\n",
       "        -1.7806e-01, -2.5700e-02, -3.6620e-02,  1.1048e-01,  7.9740e-02,\n",
       "        -5.1660e-02, -3.0020e-02,  9.8540e-02,  1.0432e-01, -1.7940e-01,\n",
       "         5.8220e-02, -1.0228e-01, -5.6840e-02,  2.6180e-02,  6.7600e-03,\n",
       "        -1.6020e-02,  2.8760e-02,  2.6780e-02,  6.0700e-02, -2.4620e-02,\n",
       "         2.9280e-02,  7.2400e-03, -3.2160e-02, -5.3420e-02, -6.8480e-02,\n",
       "        -2.2520e-02,  8.0200e-03, -2.1120e-02,  2.3540e-02, -5.5780e-02,\n",
       "         5.5800e-03, -7.2280e-02, -6.4002e-01,  8.4940e-02,  9.2760e-02,\n",
       "         1.9000e-02,  7.5400e-03, -3.5020e-02,  1.2560e-02, -6.1280e-02,\n",
       "        -2.3620e-02, -6.9740e-02,  5.4220e-02, -1.4960e-02,  5.1580e-02,\n",
       "        -4.0140e-02,  1.4380e-02,  5.1360e-02,  1.7780e-02, -6.3580e-02,\n",
       "         3.5200e-03, -1.9900e-02,  2.3720e-02,  3.1940e-02, -1.0500e-02,\n",
       "         3.1340e-02,  2.5700e-02,  5.7400e-02,  1.6240e-02,  6.5460e-02,\n",
       "        -5.9200e-03,  1.1180e-02, -2.2720e-02, -1.9484e-01, -2.4320e-02,\n",
       "         6.6800e-03,  9.0400e-03, -4.5320e-02,  1.5690e-01, -5.3800e-02,\n",
       "         7.1380e-02, -9.7480e-02,  4.1820e-02, -1.8280e-02, -2.2300e-02,\n",
       "        -4.8080e-02,  1.8000e-02, -2.6180e-02, -5.8760e-02,  3.7380e-02,\n",
       "        -1.4750e-01,  3.3880e-02, -1.1500e-02, -7.9300e-02, -3.3340e-02,\n",
       "         5.4420e-02, -5.0480e-02, -8.3860e-02,  1.9340e-02,  5.2420e-02,\n",
       "        -9.4440e-02,  6.7800e-02,  5.6220e-02, -3.9740e-02, -2.8040e-02,\n",
       "        -4.2200e-03,  7.5400e-03,  1.1052e-01, -1.0262e-01, -3.2138e-01,\n",
       "        -5.6600e-03,  5.2020e-02, -1.5420e-02,  3.0800e-02,  1.7620e-02,\n",
       "         1.9072e-01, -5.8100e-02,  7.8800e-03, -1.4400e-02,  2.7800e-02,\n",
       "        -1.5400e-03,  6.4180e-02,  8.2800e-03, -2.6960e-02,  1.2580e-02,\n",
       "         3.8700e-02, -3.4400e-03,  6.9360e-02,  2.2200e-03,  7.3800e-03,\n",
       "        -5.7360e-02,  1.6120e-02, -2.2260e-02,  1.8630e-01, -1.6560e-01,\n",
       "        -8.5800e-03, -5.0880e-02,  3.0980e-02, -4.9260e-02,  1.1024e-01,\n",
       "        -2.4300e-02, -3.4000e-02, -2.3360e-02,  8.0440e-02, -2.9680e-02,\n",
       "         6.7880e-02,  7.7640e-02,  3.2000e-03, -3.9140e-02, -1.7360e-02,\n",
       "        -6.4620e-02, -2.2740e-02,  5.4840e-02, -1.3176e-01,  3.1420e-02,\n",
       "        -5.1800e-03,  7.7300e-02,  3.9800e-03, -1.2890e-01,  2.0700e-02,\n",
       "        -6.7480e-02,  3.4320e-02,  4.4580e-02,  6.2940e-02,  1.7660e-02,\n",
       "        -7.7880e-02,  2.5554e-01, -9.9340e-02,  3.6460e-02, -3.7200e-03,\n",
       "         7.4400e-03,  5.9440e-02,  1.3460e-02,  2.1200e-02,  3.6120e-02,\n",
       "        -5.9280e-02, -1.3020e-02,  5.2240e-02, -7.4460e-02,  1.0840e-02,\n",
       "         2.7800e-02, -1.0696e-01, -1.1300e-02, -4.0580e-02, -7.0000e-03,\n",
       "        -1.9560e-02,  2.0940e-02, -4.1200e-02,  1.3954e-01, -6.0620e-02,\n",
       "        -4.2780e-02, -4.1180e-02, -3.2560e-02,  5.2940e-02,  1.0272e-01,\n",
       "        -6.5340e-02, -3.8160e-02, -8.5900e-02, -5.4400e-03,  5.6020e-02,\n",
       "         8.0080e-02,  5.4920e-02, -1.1310e-01, -2.9200e-02, -3.8920e-02,\n",
       "         2.4660e-02, -5.9200e-02,  3.7020e-02, -9.2720e-02, -6.7260e-02,\n",
       "         4.1000e-03, -1.4580e-02,  7.0760e-02,  2.8300e-02,  3.9000e-03,\n",
       "        -1.8624e-01,  1.0760e-02,  6.6740e-02, -6.1860e-02, -2.5820e-02,\n",
       "         1.4400e-03,  7.9280e-02,  3.2304e-01,  4.2400e-03, -1.5540e-02,\n",
       "        -1.5364e-01, -1.1248e-01,  1.6580e-02, -2.4138e-01,  6.1240e-02,\n",
       "        -3.1040e-02,  4.8960e-02, -7.3180e-02, -4.4600e-02,  1.3260e-02,\n",
       "        -2.2220e-02,  1.0020e-02, -5.1020e-02, -8.4400e-03,  3.6086e-01,\n",
       "         4.9700e-02, -4.4700e-02,  7.8220e-02, -4.0780e-02,  3.4600e-02,\n",
       "         3.4920e-02, -3.3540e-02,  8.4840e-02, -3.1280e-02, -1.8640e-02,\n",
       "        -4.7520e-02,  5.2820e-02,  2.4680e-02,  6.8800e-03, -3.9564e-01,\n",
       "         8.6600e-03, -7.3540e-02,  8.7480e-02, -1.2926e-01,  3.9740e-02,\n",
       "        -4.5240e-02,  9.8020e-02, -3.1060e-02, -5.4200e-02,  1.4480e-02,\n",
       "        -5.9580e-02, -2.9000e-02, -7.9740e-02, -1.6880e-02, -1.2360e-02,\n",
       "        -6.2620e-02,  3.8060e-02,  4.0960e-02,  4.8320e-02,  4.9620e-02,\n",
       "        -2.6260e-02, -5.3780e-02, -1.6380e-02, -2.3000e-03, -9.6000e-03,\n",
       "         3.2500e-02, -1.0294e-01, -4.4780e-02, -1.5520e-02,  1.0778e-01,\n",
       "         8.4660e-02, -9.1400e-03,  4.7360e-02,  5.7120e-02,  2.8700e-02])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions_dict['174390']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:57<00:00,  8.52it/s]\n"
     ]
    }
   ],
   "source": [
    "for key in tqdm(captions_dict.keys()):\n",
    "    tfidf_pred = tfidf_model.predict(captions_dict[key]['tfidf'])\n",
    "    rtfidf_pred = rtfidf_model.predict(captions_dict[key]['r-tfidf'])\n",
    "    w2v_pred = w2v_model.predict(captions_dict[key]['w2v'].reshape(-1,300))\n",
    "      \n",
    "    tfidf_dist, tfidf_idxs = tree.query(tfidf_pred/np.linalg.norm(tfidf_pred), k=10)\n",
    "    rtfidf_dist, rtfidf_idxs = tree.query(rtfidf_pred/np.linalg.norm(rtfidf_pred), k=10)\n",
    "    w2v_dist, w2v_idxs = tree.query(w2v_pred/np.linalg.norm(w2v_pred), k=10)\n",
    "    \n",
    "    tfidf_images = [order[i] for i in tfidf_idxs[0]] \n",
    "    rtfidf_images = [order[i] for i in rtfidf_idxs[0]]\n",
    "    w2v_images = [order[i] for i in w2v_idxs[0]]\n",
    "    \n",
    "    tfidf_paths = [params.VAL_IMAGES_PATH + os.path.basename(image).split('.')[0][4:]+'.jpg' for image in tfidf_images]\n",
    "    rtfidf_paths = [params.VAL_IMAGES_PATH + os.path.basename(image).split('.')[0][4:]+'.jpg' for image in rtfidf_images]\n",
    "    w2v_paths = [params.VAL_IMAGES_PATH + os.path.basename(image).split('.')[0][4:]+'.jpg' for image in w2v_images]\n",
    "    \n",
    "    captions_dict[key]['vlad_tfidf_paths'] = tfidf_paths\n",
    "    captions_dict[key]['vlad_rtfidf_paths'] = rtfidf_paths\n",
    "    captions_dict[key]['vlad_w2v_paths'] = w2v_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utils.savePickle(captions_dict,'TMP/vlad_captions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphabet = ['C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', \n",
    "            'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:30<00:00,  3.29it/s]\n",
      "100%|██████████| 100/100 [00:34<00:00,  2.89it/s]\n",
      "100%|██████████| 100/100 [00:34<00:00,  2.88it/s]\n",
      "100%|██████████| 100/100 [00:33<00:00,  3.01it/s]\n",
      "100%|██████████| 100/100 [00:25<00:00,  3.86it/s]\n",
      "100%|██████████| 100/100 [00:25<00:00,  3.97it/s]\n",
      "100%|██████████| 100/100 [00:28<00:00,  3.53it/s]\n",
      "100%|██████████| 100/100 [00:27<00:00,  3.65it/s]\n",
      "100%|██████████| 100/100 [00:27<00:00,  3.68it/s]\n",
      "100%|██████████| 100/100 [00:27<00:00,  3.70it/s]\n"
     ]
    }
   ],
   "source": [
    "for counter in range(10):\n",
    "    tfidf_workbook = xlsxwriter.Workbook('EXCELS/VLAD/TFIDF_VLAD/tfidf_vlad_{}.xlsx'.format(counter))\n",
    "    tfidf_worksheet = tfidf_workbook.add_worksheet()\n",
    "    tfidf_worksheet.set_column('A:A', 10)\n",
    "    tfidf_worksheet.set_column('B:B', 60)\n",
    "    tfidf_worksheet.write('A1','POSITION')\n",
    "\n",
    "    j = 4\n",
    "    for key in tqdm(list(captions_dict.keys())[counter*100:counter*100+100]):\n",
    "        caption = captions_dict[key]['caption']\n",
    "        tfidf_paths = captions_dict[key]['vlad_tfidf_paths']\n",
    "        #rtfidf_paths = captions_dict[key]['rtfidf_paths']\n",
    "        #w2v_paths = captions_dict[key]['w2v_paths']\n",
    "\n",
    "\n",
    "\n",
    "        tfidf_worksheet.write('B{}'.format(j), caption)\n",
    "        for i, path in enumerate(tfidf_paths):\n",
    "            img = image.load_img(path, target_size=(224, 224))\n",
    "            name = 'CROP/'+os.path.basename(path)\n",
    "            image.save_img(name, img)\n",
    "            tfidf_worksheet.insert_image('{}{}'.format(alphabet[i*2], j-2), \n",
    "                                         name, \n",
    "                                         {'x_scale': 0.5, 'y_scale': 0.5})\n",
    "\n",
    "        j = j+6\n",
    "    tfidf_workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:27<00:00,  3.65it/s]\n",
      "100%|██████████| 100/100 [00:26<00:00,  3.73it/s]\n",
      "100%|██████████| 100/100 [00:26<00:00,  3.73it/s]\n",
      "100%|██████████| 100/100 [00:27<00:00,  3.66it/s]\n",
      "100%|██████████| 100/100 [00:26<00:00,  3.82it/s]\n",
      "100%|██████████| 100/100 [00:26<00:00,  3.84it/s]\n",
      "100%|██████████| 100/100 [00:26<00:00,  3.72it/s]\n",
      "100%|██████████| 100/100 [00:26<00:00,  3.75it/s]\n",
      "100%|██████████| 100/100 [00:26<00:00,  3.71it/s]\n",
      "100%|██████████| 100/100 [00:26<00:00,  3.74it/s]\n"
     ]
    }
   ],
   "source": [
    "for counter in range(10):\n",
    "    rtfidf_workbook = xlsxwriter.Workbook('EXCELS/VLAD/R-TFIDF_VLAD/rtfidf_vlad_{}.xlsx'.format(counter))\n",
    "    rtfidf_worksheet = rtfidf_workbook.add_worksheet()\n",
    "    rtfidf_worksheet.set_column('A:A', 10)\n",
    "    rtfidf_worksheet.set_column('B:B', 60)\n",
    "    rtfidf_worksheet.write('A1','POSITION')\n",
    "\n",
    "    j = 4\n",
    "    for key in tqdm(list(captions_dict.keys())[counter*100:counter*100+100]):\n",
    "        caption = captions_dict[key]['caption']\n",
    "        rtfidf_paths = captions_dict[key]['vlad_rtfidf_paths']\n",
    "        #rtfidf_paths = captions_dict[key]['rtfidf_paths']\n",
    "        #w2v_paths = captions_dict[key]['w2v_paths']\n",
    "\n",
    "\n",
    "\n",
    "        rtfidf_worksheet.write('B{}'.format(j), caption)\n",
    "        for i, path in enumerate(rtfidf_paths):\n",
    "            img = image.load_img(path, target_size=(224, 224))\n",
    "            name = 'CROP/'+os.path.basename(path)\n",
    "            image.save_img(name, img)\n",
    "            rtfidf_worksheet.insert_image('{}{}'.format(alphabet[i*2], j-2), \n",
    "                                         name, \n",
    "                                         {'x_scale': 0.5, 'y_scale': 0.5})\n",
    "\n",
    "        j = j+6\n",
    "    rtfidf_workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:27<00:00,  3.67it/s]\n",
      "100%|██████████| 100/100 [00:26<00:00,  3.72it/s]\n",
      "100%|██████████| 100/100 [00:26<00:00,  3.77it/s]\n",
      "100%|██████████| 100/100 [00:26<00:00,  3.75it/s]\n",
      "100%|██████████| 100/100 [00:27<00:00,  3.69it/s]\n",
      "100%|██████████| 100/100 [00:24<00:00,  4.07it/s]\n",
      "100%|██████████| 100/100 [00:25<00:00,  3.92it/s]\n",
      "100%|██████████| 100/100 [00:24<00:00,  4.04it/s]\n",
      "100%|██████████| 100/100 [00:25<00:00,  3.89it/s]\n",
      "100%|██████████| 100/100 [00:27<00:00,  3.70it/s]\n"
     ]
    }
   ],
   "source": [
    "for counter in range(10):\n",
    "    w2v_workbook = xlsxwriter.Workbook('EXCELS/VLAD/W2V_VLAD/w2v_vlad_{}.xlsx'.format(counter))\n",
    "    w2v_worksheet = w2v_workbook.add_worksheet()\n",
    "    w2v_worksheet.set_column('A:A', 10)\n",
    "    w2v_worksheet.set_column('B:B', 60)\n",
    "    w2v_worksheet.write('A1','POSITION')\n",
    "\n",
    "    j = 4\n",
    "    for key in tqdm(list(captions_dict.keys())[counter*100:counter*100+100]):\n",
    "        caption = captions_dict[key]['caption']\n",
    "        w2v_paths = captions_dict[key]['vlad_w2v_paths']\n",
    "        #rtfidf_paths = captions_dict[key]['rtfidf_paths']\n",
    "        #w2v_paths = captions_dict[key]['w2v_paths']\n",
    "\n",
    "\n",
    "\n",
    "        w2v_worksheet.write('B{}'.format(j), caption)\n",
    "        for i, path in enumerate(w2v_paths):\n",
    "            img = image.load_img(path, target_size=(224, 224))\n",
    "            name = 'CROP/'+os.path.basename(path)\n",
    "            image.save_img(name, img)\n",
    "            w2v_worksheet.insert_image('{}{}'.format(alphabet[i*2], j-2), \n",
    "                                         name, \n",
    "                                         {'x_scale': 0.5, 'y_scale': 0.5})\n",
    "\n",
    "        j = j+6\n",
    "    w2v_workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
